# -*- coding: utf-8 -*-
"""Untitled7.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Bd0PeQ3KlWLwCwPnE2970NQfj6kNFbiX
"""

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report

# Sample Breast Cancer Data (replace with your actual data)
data = {'radius_mean': [13.0, 17.0, 18.0, 12.0, 15.0, 11.0, 14.0, 15.0, 10.0, 16.0],
        'texture_mean': [21.0, 25.0, 16.0, 20.0, 23.0, 17.0, 18.0, 20.0, 13.0, 22.0],
        'smoothness_mean': [85.0, 102.0, 97.0, 80.0, 88.0, 70.0, 75.0, 72.0, 65.0, 78.0],
        'diagnosis': ['M', 'M', 'B', 'B', 'M', 'B', 'B', 'M', 'B', 'M']}

df = pd.DataFrame(data)

# Convert 'diagnosis' column to numerical values (0: Benign, 1: Malignant)
lb = LabelEncoder()
df['diagnosis'] = lb.fit_transform(df['diagnosis'])

# Split data into features (X) and target variable (y)
X = df.drop(columns=['diagnosis'])
y = df['diagnosis']

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)

# Standardize features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Train a logistic regression model with L2 regularization
logistic_model = LogisticRegression(random_state=0, penalty='l2', C=1.0)
logistic_model.fit(X_train_scaled, y_train)

# Model evaluation
y_pred = logistic_model.predict(X_test_scaled)
print(classification_report(y_test, y_pred))

# Data Visualization - Pairplot
sns.pairplot(df, hue='diagnosis')
plt.show()

# Feature Importance
# (Logistic regression doesn't provide inherent feature importance)
# You can use techniques like permutation importance with other models

print("Regularization parameter (C):", logistic_model.C)

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error

def preprocess_data(data):
    """Preprocesses the data by handling missing values and converting categorical columns."""

    # Use forward fill (ffill) to handle missing values
    data.fillna(method='ffill', inplace=True)

    # Assuming 'Diagnosis' is a categorical column
    categorical_columns = ['diagnosis']
    for col in categorical_columns:
        # Ensure data type compatibility before applying factorize
        if not pd.api.types.is_string_dtype(data[col]):
            data[col] = data[col].astype(str)
        data[col] = pd.factorize(data[col])[0]

    return data

def visualize_data(data):
    """Visualizes the data using pair plots and bar charts."""
    try:
        sns.pairplot(data)
        plt.show()
    except Exception as e:
        print("Error creating pair plot:", e)

    # Randomly select a column for visualization
    import random
    column_to_visualize = data.columns[random.randint(0, len(data.columns) - 1)]
    sns.countplot(x=column_to_visualize, data=data)
    plt.show()

def build_and_evaluate_model(data, target_column):
    """Builds and evaluates the linear regression model."""
    X = data.drop(target_column, axis=1)
    y = data[target_column]

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    model = LinearRegression()
    model.fit(X_train, y_train)
    predictions = model.predict(X_test)
    mse = mean_squared_error(y_test, predictions)
    print(f"Mean Squared Error: {mse:.2f}")

    return model, mse

def predict_with_user_input(model):
    """Predicts using user input."""
    new_data = []
    # Get input values from user
    # Append values to new_data list

    prediction = model.predict([new_data])
    print("Prediction:", prediction)

# Load your dataset
data = pd.read_csv('breast cancer pridiction data set.csv')

# Preprocess data
data = preprocess_data(data)

# Visualize data
visualize_data(data)

# Choose a target column
target_column = 'smoothness_mean'  # Replace with the actual target column

# Build and evaluate the model
model, mse = build_and_evaluate_model(data, target_column)

# Predict with user input (optional)
# predict_with_user_input(model)

# Create a heatmap
correlation_matrix = data.corr()
sns.heatmap(correlation_matrix, annot=True)
plt.show()